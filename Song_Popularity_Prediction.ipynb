{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Song Popularity Prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfTQ2h8DBDmzMepLc87oB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajebbar/Neural-Oblivious-Decision-Ensembles/blob/main/Song_Popularity_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons --quiet"
      ],
      "metadata": {
        "id": "mp8Lfm2STmrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77sLtEVUTSO_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers as L\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_probability import distributions, stats\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "metadata": {
        "id": "MADcNaXpULrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "url = 'https://www.kaggle.com/c/song-popularity-prediction/data'\n",
        "od.download(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtG5xuQpUNX_",
        "outputId": "1b3dbd72-d1dd-4cfb-e70d-3c6a8e40bdff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./song-popularity-prediction\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = './song-popularity-prediction'\n",
        "\n",
        "os.listdir(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hee4IslKUWmN",
        "outputId": "a32bdac7-147b-4d12-fa90-8c62db31cbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv', 'sample_submission.csv', 'test.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = data_dir + '/train.csv'\n",
        "test_csv = data_dir + '/test.csv'\n",
        "submission_csv = data_dir + '/sample_submission.csv'"
      ],
      "metadata": {
        "id": "kzMIidVPUa0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(train_csv)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xPAoPe7ITVZ6",
        "outputId": "0c7c48f3-6af1-4e04-a27f-82162067d7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 15)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-65531542-bcd7-4e43-98b0-56eba308c526\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>song_duration_ms</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>key</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>audio_mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>audio_valence</th>\n",
              "      <th>song_popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>212990.0</td>\n",
              "      <td>0.642286</td>\n",
              "      <td>0.856520</td>\n",
              "      <td>0.707073</td>\n",
              "      <td>0.002001</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.619088</td>\n",
              "      <td>0</td>\n",
              "      <td>0.082570</td>\n",
              "      <td>158.386236</td>\n",
              "      <td>4</td>\n",
              "      <td>0.734642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.054866</td>\n",
              "      <td>0.733289</td>\n",
              "      <td>0.835545</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.436428</td>\n",
              "      <td>-5.236965</td>\n",
              "      <td>1</td>\n",
              "      <td>0.127358</td>\n",
              "      <td>102.752988</td>\n",
              "      <td>3</td>\n",
              "      <td>0.711531</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>193213.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.188387</td>\n",
              "      <td>0.783524</td>\n",
              "      <td>-0.002694</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.170499</td>\n",
              "      <td>-4.951759</td>\n",
              "      <td>0</td>\n",
              "      <td>0.052282</td>\n",
              "      <td>178.685791</td>\n",
              "      <td>3</td>\n",
              "      <td>0.425536</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>249893.0</td>\n",
              "      <td>0.488660</td>\n",
              "      <td>0.585234</td>\n",
              "      <td>0.552685</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094805</td>\n",
              "      <td>-7.893694</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035618</td>\n",
              "      <td>128.715630</td>\n",
              "      <td>3</td>\n",
              "      <td>0.453597</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>165969.0</td>\n",
              "      <td>0.493017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.740982</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.094891</td>\n",
              "      <td>-2.684095</td>\n",
              "      <td>0</td>\n",
              "      <td>0.050746</td>\n",
              "      <td>121.928157</td>\n",
              "      <td>4</td>\n",
              "      <td>0.741311</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65531542-bcd7-4e43-98b0-56eba308c526')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65531542-bcd7-4e43-98b0-56eba308c526 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65531542-bcd7-4e43-98b0-56eba308c526');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  song_duration_ms  ...  audio_valence  song_popularity\n",
              "0   0          212990.0  ...       0.734642                0\n",
              "1   1               NaN  ...       0.711531                1\n",
              "2   2          193213.0  ...       0.425536                0\n",
              "3   3          249893.0  ...       0.453597                0\n",
              "4   4          165969.0  ...       0.741311                0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(test_csv)\n",
        "X_test = test.drop(['id'], axis=1)"
      ],
      "metadata": {
        "id": "lWwpDCLUUgoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['id', 'song_popularity'], axis=1)\n",
        "y = data['song_popularity']"
      ],
      "metadata": {
        "id": "HVv1T3YqUqTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "n1_pqhN1UyMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "4LXJ7DzjU4n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def sparsemoid(inputs):\n",
        "    return tf.clip_by_value(0.5 * inputs + 0.5, 0., 1.)\n",
        "\n",
        "\n",
        "def get_binary_lookup_table(depth):\n",
        "    # output: binary tensor [depth, 2**depth, 2]\n",
        "    indices = tf.keras.backend.arange(0, 2**depth, 1)\n",
        "    offsets = 2 ** tf.keras.backend.arange(0, depth, 1)\n",
        "    bin_codes = (tf.reshape(indices, (1, -1)) // tf.reshape(offsets, (-1, 1)) % 2)\n",
        "    bin_codes = tf.stack([bin_codes, 1 - bin_codes], axis=-1)\n",
        "    bin_codes = tf.cast(bin_codes, 'float32')\n",
        "    binary_lut = tf.Variable(initial_value=bin_codes, trainable=False)\n",
        "    return binary_lut\n",
        "\n",
        "\n",
        "def get_feature_selection_logits(n_trees, depth, dim):\n",
        "    initializer = tf.keras.initializers.random_uniform()\n",
        "    init_shape = (dim, n_trees, depth)\n",
        "    init_value = initializer(shape=init_shape, dtype='float32')\n",
        "    return tf.Variable(init_value, trainable=True)\n",
        "\n",
        "\n",
        "def get_output_response(n_trees, depth, units):\n",
        "    initializer = tf.keras.initializers.random_uniform()\n",
        "    init_shape = (n_trees, units, 2**depth)\n",
        "    init_value = initializer(init_shape, dtype='float32')\n",
        "    return tf.Variable(initial_value=init_value, trainable=True)\n",
        "\n",
        "\n",
        "def get_feature_thresholds(n_trees, depth):\n",
        "    initializer = tf.ones_initializer()\n",
        "    init_shape = (n_trees, depth)\n",
        "    init_value = initializer(shape=init_shape, dtype='float32')\n",
        "    return tf.Variable(init_value, trainable=True)\n",
        "\n",
        "\n",
        "def get_log_temperatures(n_trees, depth):\n",
        "    initializer = tf.ones_initializer()\n",
        "    init_shape = (n_trees, depth)\n",
        "    init_value = initializer(shape=init_shape, dtype='float32')\n",
        "    return tf.Variable(initial_value=init_value, trainable=True)\n",
        "\n",
        "\n",
        "def init_feature_thresholds(features, beta, n_trees, depth):\n",
        "    sampler = distributions.Beta(beta, beta)\n",
        "    percentiles_q = sampler.sample([n_trees * depth])\n",
        "\n",
        "    flattened_feature_values = tf.map_fn(tf.keras.backend.flatten, features)\n",
        "    percentile = stats.percentile(flattened_feature_values, 100*percentiles_q)\n",
        "    feature_thresholds = tf.reshape(percentile, (n_trees, depth))\n",
        "    return feature_thresholds\n",
        "\n",
        "\n",
        "def init_log_temperatures(features, feature_thresholds):\n",
        "    input_threshold_diff = tf.math.abs(features - feature_thresholds)\n",
        "    log_temperatures = stats.percentile(input_threshold_diff, 50, axis=0)\n",
        "    return log_temperatures"
      ],
      "metadata": {
        "id": "XJ8mL2HbU3ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ObliviousDecisionTree(L.Layer):\n",
        "    def __init__(self,n_trees=3, depth=4, units=1,threshold_init_beta=1.):\n",
        "        super().__init__()\n",
        "        self.initialized = False\n",
        "        self.n_trees = n_trees\n",
        "        self.depth = depth\n",
        "        self.units = units\n",
        "        self.threshold_init_beta = threshold_init_beta\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[-1]\n",
        "        n_trees, depth, units = self.n_trees, self.depth, self.units\n",
        "        self.feature_selection_logits = get_feature_selection_logits(n_trees, depth, dim)\n",
        "        self.feature_thresholds = get_feature_thresholds(n_trees, depth)\n",
        "        self.log_temperatures = get_log_temperatures(n_trees, depth)\n",
        "        self.binary_lut = get_binary_lookup_table(depth)\n",
        "        self.response = get_output_response(n_trees, depth, units)\n",
        "\n",
        "    def _data_aware_initialization(self, inputs):\n",
        "        beta, n_trees, depth = self.threshold_init_beta, self.n_trees, self.depth\n",
        "        feature_values = self._get_feature_values(inputs)\n",
        "        feature_thresholds = init_feature_thresholds(feature_values, beta, n_trees, depth)\n",
        "        log_temperatures = init_log_temperatures(feature_values, feature_thresholds)\n",
        "        self.feature_thresholds.assign(feature_thresholds)\n",
        "        self.log_temperatures.assign(log_temperatures)\n",
        "\n",
        "    def _get_feature_values(self, inputs, training=None):\n",
        "        feature_selectors = tfa.activations.sparsemax(self.feature_selection_logits)\n",
        "        feature_values = tf.einsum('bi,ind->bnd', inputs, feature_selectors)\n",
        "        return feature_values\n",
        "\n",
        "    def _get_feature_gates(self, feature_values):\n",
        "        threshold_logits = (feature_values - self.feature_thresholds)\n",
        "        threshold_logits = threshold_logits * tf.math.exp(-self.log_temperatures)\n",
        "        threshold_logits = tf.stack([-threshold_logits, threshold_logits], axis=-1)\n",
        "        feature_gates = sparsemoid(threshold_logits)\n",
        "        return feature_gates\n",
        "\n",
        "    def _get_aggregated_response(self, feature_gates):\n",
        "        aggregated_gates = tf.einsum('bnds,dcs->bndc', feature_gates, self.binary_lut)\n",
        "        aggregated_gates = tf.math.reduce_prod(aggregated_gates, axis=-2)\n",
        "        aggregated_response = tf.einsum('bnc,nuc->bnu', aggregated_gates, self.response)\n",
        "        return aggregated_response\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if not self.initialized:\n",
        "            self._data_aware_initialization(inputs)\n",
        "            self.initialized = True\n",
        "\n",
        "        feature_values = self._get_feature_values(inputs)\n",
        "        feature_gates = self._get_feature_gates(feature_values)\n",
        "        aggregated_response = self._get_aggregated_response(feature_gates)\n",
        "        response_averaged_over_trees = tf.reduce_mean(aggregated_response, axis=1)\n",
        "        return response_averaged_over_trees"
      ],
      "metadata": {
        "id": "zM1YBMcFVRnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NODE(keras.Model):\n",
        "    def __init__(self, units=1, n_layers=1, link=tf.identity, n_trees=3, tree_depth=4, threshold_init_beta=1):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.n_layers = n_layers\n",
        "        self.n_trees = n_trees\n",
        "        self.tree_depth = tree_depth\n",
        "        self.units = units\n",
        "        self.threshold_init_beta = threshold_init_beta\n",
        "\n",
        "        self.bn = L.BatchNormalization()\n",
        "        self.ensemble = [ObliviousDecisionTree(\n",
        "            n_trees=n_trees, depth=tree_depth, units=units,threshold_init_beta=threshold_init_beta\n",
        "        ) for _ in range(n_layers)]\n",
        "        self.link = link\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.bn(inputs, training=training)\n",
        "        for tree in self.ensemble:\n",
        "            h = tree(x)\n",
        "            x = tf.concat([x, h], axis=1)\n",
        "        return self.link(h)"
      ],
      "metadata": {
        "id": "5-MtDZTkVewg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_cat_pipeline = lambda: Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
        "    ('encoder', OneHotEncoder(sparse=False))\n",
        "])\n",
        "\n",
        "get_num_pipeline = lambda: Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')), \n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "KC0rXBySVnBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model_config:\n",
        "    NUMERIC_FEATURE_NAMES=[\n",
        "        'song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness',\n",
        "        'speechiness', 'tempo', 'audio_valence'\n",
        "    ]\n",
        "    CATEGORICAL_FEATURE_NAMES=[\n",
        "        'key','audio_mode','time_signature'   \n",
        "    ]\n",
        "\n",
        "MAX_EPOCHS  = 100\n",
        "\n",
        "get_callbacks = lambda : [\n",
        "    keras.callbacks.EarlyStopping(min_delta=1e-4, patience=10, verbose=1, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "SPTsxSMEVsca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "YyXN8K9AV1bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "    num_pipeline = get_num_pipeline().fit(X_train[model_config.NUMERIC_FEATURE_NAMES])\n",
        "    cat_pipeline = get_cat_pipeline().fit(X_train[model_config.CATEGORICAL_FEATURE_NAMES])\n",
        "    \n",
        "    X_train = np.hstack((\n",
        "        num_pipeline.transform(X_train[model_config.NUMERIC_FEATURE_NAMES]),\n",
        "        cat_pipeline.transform(X_train[model_config.CATEGORICAL_FEATURE_NAMES])\n",
        "    ))\n",
        "    X_valid = np.hstack((\n",
        "        num_pipeline.transform(X_valid[model_config.NUMERIC_FEATURE_NAMES]),\n",
        "        cat_pipeline.transform(X_valid[model_config.CATEGORICAL_FEATURE_NAMES])\n",
        "    ))\n",
        "    X_test_ = np.hstack((\n",
        "        num_pipeline.transform(X_test[model_config.NUMERIC_FEATURE_NAMES]),\n",
        "        cat_pipeline.transform(X_test[model_config.CATEGORICAL_FEATURE_NAMES])\n",
        "    ))\n",
        "    \n",
        "    model = NODE()\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        X_train, y_train, validation_data=(X_valid, y_valid), callbacks=get_callbacks(), \n",
        "        epochs=MAX_EPOCHS\n",
        "    )  \n",
        "    preds.append(model.predict(X_test_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciESBZIpV0Rw",
        "outputId": "3d82339b-1910-4b1b-ca26-e3e00843eb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.7901 - accuracy: 0.6356 - val_loss: 0.6611 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6564 - accuracy: 0.6356 - val_loss: 0.6594 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6561 - accuracy: 0.6356 - val_loss: 0.6587 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6570 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6570 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6589 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6553 - accuracy: 0.6356 - val_loss: 0.6568 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6544 - accuracy: 0.6356 - val_loss: 0.6568 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6573 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1106/1125 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.6355\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6580 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6581 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6575 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1124/1125 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6357\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6570 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6535 - accuracy: 0.6356 - val_loss: 0.6569 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6573 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "1112/1125 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.6360\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6574 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "1115/1125 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6355Restoring model weights from the end of the best epoch: 7.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6580 - val_accuracy: 0.6357 - lr: 1.0000e-06\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1106/1125 [============================>.] - ETA: 0s - loss: 5.6148 - accuracy: 0.6360\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "1116/1125 [============================>.] - ETA: 0s - loss: 5.6246 - accuracy: 0.6354\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "1114/1125 [============================>.] - ETA: 0s - loss: 5.6277 - accuracy: 0.6352\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "1113/1125 [============================>.] - ETA: 0s - loss: 5.6250 - accuracy: 0.6353Restoring model weights from the end of the best epoch: 1.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 5.6211 - accuracy: 0.6356 - val_loss: 5.6185 - val_accuracy: 0.6357 - lr: 1.0000e-06\n",
            "Epoch 00011: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.8578 - accuracy: 0.6356 - val_loss: 0.6691 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6590 - accuracy: 0.6356 - val_loss: 0.6562 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6564 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6562 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6559 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6559 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6559 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6551 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6542 - accuracy: 0.6356 - val_loss: 0.6526 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6525 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6524 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6525 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1121/1125 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.6356\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6526 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6557 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "1105/1125 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.6352\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6555 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "1105/1125 [============================>.] - ETA: 0s - loss: 0.6542 - accuracy: 0.6351\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6557 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "1123/1125 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.6354Restoring model weights from the end of the best epoch: 13.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6357 - lr: 1.0000e-06\n",
            "Epoch 00023: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.9376 - accuracy: 0.6356 - val_loss: 0.6829 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6649 - accuracy: 0.6356 - val_loss: 0.6570 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6543 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6542 - accuracy: 0.6356 - val_loss: 0.6529 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6520 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6525 - accuracy: 0.6354 - val_loss: 0.6515 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6522 - accuracy: 0.6354 - val_loss: 0.6511 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6521 - accuracy: 0.6354 - val_loss: 0.6511 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6518 - accuracy: 0.6355 - val_loss: 0.6513 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1117/1125 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.6353\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6518 - accuracy: 0.6354 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6508 - accuracy: 0.6353 - val_loss: 0.6511 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6508 - accuracy: 0.6354 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1117/1125 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.6356\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6511 - accuracy: 0.6355 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6511 - accuracy: 0.6355 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6509 - accuracy: 0.6355 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "1108/1125 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.6348\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6509 - accuracy: 0.6354 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "1102/1125 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.6352Restoring model weights from the end of the best epoch: 7.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6508 - accuracy: 0.6355 - val_loss: 0.6512 - val_accuracy: 0.6357 - lr: 1.0000e-06\n",
            "Epoch 00017: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.9742 - accuracy: 0.6356 - val_loss: 0.6741 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6620 - accuracy: 0.6356 - val_loss: 0.6574 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6565 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6553 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6544 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6539 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6526 - accuracy: 0.6356 - val_loss: 0.6533 - val_accuracy: 0.6352 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6525 - accuracy: 0.6352 - val_loss: 0.6534 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6520 - accuracy: 0.6355 - val_loss: 0.6535 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1106/1125 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.6362\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6521 - accuracy: 0.6356 - val_loss: 0.6533 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6516 - accuracy: 0.6355 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6516 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6515 - accuracy: 0.6355 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "1124/1125 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.6356\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "1101/1125 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.6353\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 19/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 20/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6516 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 21/100\n",
            "1107/1125 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.6352\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6516 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 22/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6515 - accuracy: 0.6355 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-07\n",
            "Epoch 23/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-07\n",
            "Epoch 24/100\n",
            "1122/1125 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.6356\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-07\n",
            "Epoch 25/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-08\n",
            "Epoch 26/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6532 - val_accuracy: 0.6355 - lr: 1.0000e-08\n",
            "Epoch 27/100\n",
            "1108/1125 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.6355\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6514 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-08\n",
            "Epoch 28/100\n",
            "1120/1125 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.6355Restoring model weights from the end of the best epoch: 18.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6515 - accuracy: 0.6356 - val_loss: 0.6531 - val_accuracy: 0.6355 - lr: 1.0000e-09\n",
            "Epoch 00028: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.8703 - accuracy: 0.6356 - val_loss: 0.6792 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6613 - accuracy: 0.6356 - val_loss: 0.6573 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6571 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6558 - accuracy: 0.6356 - val_loss: 0.6574 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6554 - accuracy: 0.6356 - val_loss: 0.6571 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6545 - accuracy: 0.6356 - val_loss: 0.6564 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6566 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6528 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6524 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1104/1125 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.6351\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6522 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6356 - val_loss: 0.6551 - val_accuracy: 0.6352 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6352 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6355 - val_loss: 0.6556 - val_accuracy: 0.6352 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "1109/1125 [============================>.] - ETA: 0s - loss: 0.6517 - accuracy: 0.6357\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6355 - val_loss: 0.6560 - val_accuracy: 0.6352 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6355 - val_loss: 0.6550 - val_accuracy: 0.6352 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6520 - accuracy: 0.6356 - val_loss: 0.6554 - val_accuracy: 0.6352 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6355 - val_loss: 0.6559 - val_accuracy: 0.6352 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "1125/1125 [==============================] - ETA: 0s - loss: 0.6519 - accuracy: 0.6356\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6356 - val_loss: 0.6556 - val_accuracy: 0.6352 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6355 - val_loss: 0.6555 - val_accuracy: 0.6352 - lr: 1.0000e-06\n",
            "Epoch 21/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6520 - accuracy: 0.6355 - val_loss: 0.6558 - val_accuracy: 0.6352 - lr: 1.0000e-06\n",
            "Epoch 22/100\n",
            "1109/1125 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.6355\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6519 - accuracy: 0.6354 - val_loss: 0.6552 - val_accuracy: 0.6352 - lr: 1.0000e-06\n",
            "Epoch 23/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6356 - val_loss: 0.6562 - val_accuracy: 0.6352 - lr: 1.0000e-07\n",
            "Epoch 24/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6520 - accuracy: 0.6355 - val_loss: 0.6550 - val_accuracy: 0.6352 - lr: 1.0000e-07\n",
            "Epoch 25/100\n",
            "1106/1125 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.6358\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6518 - accuracy: 0.6356 - val_loss: 0.6559 - val_accuracy: 0.6352 - lr: 1.0000e-07\n",
            "Epoch 26/100\n",
            "1113/1125 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.6355Restoring model weights from the end of the best epoch: 16.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6518 - accuracy: 0.6356 - val_loss: 0.6559 - val_accuracy: 0.6352 - lr: 1.0000e-08\n",
            "Epoch 00026: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 0.8762 - accuracy: 0.6356 - val_loss: 0.6796 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6622 - accuracy: 0.6356 - val_loss: 0.6572 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 2s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6568 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6568 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6556 - accuracy: 0.6356 - val_loss: 0.6560 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6547 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6552 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1104/1125 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.6356\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6538 - accuracy: 0.6356 - val_loss: 0.6545 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6551 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6547 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6543 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6545 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "1105/1125 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6355\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6548 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6535 - accuracy: 0.6356 - val_loss: 0.6549 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "1103/1125 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.6354\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6545 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 22/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6558 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 23/100\n",
            "1118/1125 [============================>.] - ETA: 0s - loss: 0.6536 - accuracy: 0.6354\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 24/100\n",
            "1102/1125 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.6360Restoring model weights from the end of the best epoch: 14.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 1.0000e-07\n",
            "Epoch 00024: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.7624 - accuracy: 0.6356 - val_loss: 0.6596 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6563 - accuracy: 0.6356 - val_loss: 0.6593 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6589 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6590 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6557 - accuracy: 0.6356 - val_loss: 0.6589 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6551 - accuracy: 0.6356 - val_loss: 0.6580 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6540 - accuracy: 0.6356 - val_loss: 0.6586 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6594 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1112/1125 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.6357\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6606 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6604 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6605 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "1108/1125 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.6354\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6605 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6600 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6616 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "1112/1125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.6354\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6607 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "1122/1125 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.6356Restoring model weights from the end of the best epoch: 6.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6604 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 2ms/step - loss: 0.7468 - accuracy: 0.6356 - val_loss: 0.6571 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6562 - accuracy: 0.6356 - val_loss: 0.6564 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6561 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6552 - accuracy: 0.6356 - val_loss: 0.6551 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6543 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6550 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6550 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1116/1125 [============================>.] - ETA: 0s - loss: 0.6537 - accuracy: 0.6354\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6536 - accuracy: 0.6356 - val_loss: 0.6549 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6547 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "1105/1125 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.6354\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6543 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6544 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "1115/1125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.6355\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6532 - accuracy: 0.6356 - val_loss: 0.6547 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "1118/1125 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.6357Restoring model weights from the end of the best epoch: 5.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6546 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 00015: early stopping\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "1125/1125 [==============================] - 4s 3ms/step - loss: 1.0417 - accuracy: 0.6356 - val_loss: 0.7377 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6831 - accuracy: 0.6356 - val_loss: 0.6598 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6572 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6553 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6560 - accuracy: 0.6356 - val_loss: 0.6552 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6552 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6559 - accuracy: 0.6356 - val_loss: 0.6550 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6558 - accuracy: 0.6356 - val_loss: 0.6548 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6550 - accuracy: 0.6356 - val_loss: 0.6541 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6541 - accuracy: 0.6356 - val_loss: 0.6537 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6537 - accuracy: 0.6356 - val_loss: 0.6536 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6539 - accuracy: 0.6356 - val_loss: 0.6539 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1122/1125 [============================>.] - ETA: 0s - loss: 0.6534 - accuracy: 0.6359\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6535 - accuracy: 0.6356 - val_loss: 0.6538 - val_accuracy: 0.6355 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6538 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6538 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "1121/1125 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.6357\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6531 - accuracy: 0.6356 - val_loss: 0.6537 - val_accuracy: 0.6355 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6538 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6533 - accuracy: 0.6356 - val_loss: 0.6537 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "1123/1125 [============================>.] - ETA: 0s - loss: 0.6531 - accuracy: 0.6355\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6530 - accuracy: 0.6356 - val_loss: 0.6537 - val_accuracy: 0.6355 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "1112/1125 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.6354Restoring model weights from the end of the best epoch: 10.\n",
            "1125/1125 [==============================] - 3s 2ms/step - loss: 0.6534 - accuracy: 0.6356 - val_loss: 0.6538 - val_accuracy: 0.6355 - lr: 1.0000e-06\n",
            "Epoch 00020: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "AccPxsDEWNBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissions = pd.read_csv(submission_csv)\n",
        "submissions['song_popularity'] = np.array(preds).mean(axis=0)\n",
        "submissions.to_csv('preds.csv', index=False)"
      ],
      "metadata": {
        "id": "n2mT0iM0WOrA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}